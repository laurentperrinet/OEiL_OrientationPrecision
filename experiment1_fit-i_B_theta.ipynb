{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* experiment with narrower sampling of thetas / less trials / fixed presentation time\n",
    "* analysis with train set / test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python implementation: CPython\n",
      "Python version       : 3.12.9\n",
      "IPython version      : 9.0.0\n",
      "\n",
      "numpy       : 1.26.4\n",
      "MotionClouds: 20220927\n",
      "manim       : 0.18.1\n",
      "pandas      : 2.2.3\n",
      "matplotlib  : 3.10.1\n",
      "scipy       : 1.15.2\n",
      "\n",
      "Compiler    : Clang 16.0.0 (clang-1600.0.26.6)\n",
      "OS          : Darwin\n",
      "Release     : 24.3.0\n",
      "Machine     : arm64\n",
      "Processor   : arm\n",
      "CPU cores   : 10\n",
      "Architecture: 64bit\n",
      "\n",
      "Hostname: obiwan.local\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run experiment1.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## one logistic regression per session and per B_theta\n",
    "\n",
    "Some inductive biases:\n",
    "\n",
    "* the lapse rate is independent of `B_theta`\n",
    "* the slope is parameterized for each `B_theta` and should decrease with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 6.66666667, 13.33333333, 20.        , 26.66666667, 33.33333333,\n",
       "        40.        , 46.66666667, 53.33333333, 60.        ]),\n",
       " 9)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_trials = np.array(parameters['theta'])*180/np.pi\n",
    "theta_max = theta_trials.max()\n",
    "i_B_theta_trials = np.array(parameters['i_B_theta'])\n",
    "B_thetas = np.sort(np.array(parameters['B_theta'].unique()))*180/np.pi\n",
    "# B_thetas, len(B_thetas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best params:  {'batch_size': 11, 'etab1': 0.00809674756441486, 'etab2': 7.316329267880158e-05, 'learning_rate': 0.0034469777956771435, 'amsgrad': False, 'logit0': -3.0899047872305645, 'log_wt': -2.0385721992893386}\n",
    "# Best params:  {'batch_size': 2, 'etab1': 0.021231015043172954, 'etab2': 2.2279395195458774e-05, 'learning_rate': 0.005893783241341296, 'amsgrad': True, 'logit0': -1.8636329895619623, 'log_wt': -1.9251590800881406}\n",
    "# Best params: {'batch_size': 24, 'etab1': 0.00857849501562565, 'etab2': 1.0409114152035763e-05, 'learning_rate': 0.0745990192922949, 'amsgrad': True, 'logit0': -0.08218706436646056, 'log_wt': -0.518831161760116}\n",
    "# Best value: 0.516 at 2025-03-18 08:42:49\n",
    "\n",
    "num_epochs = 2 ** 10 + 1\n",
    "learning_rate = 0.07\n",
    "etab1, etab2 = 0.00857, 1e-5\n",
    "batch_size = 24\n",
    "amsgrad = True\n",
    "logit0 = -.01\n",
    "log_wt = -.5\n",
    "theta0 = 0.\n",
    "frozen_theta0 = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TimeoutError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(torch.nn.Module):\n",
    "    def __init__(self, logit0=logit0, theta0=theta0, log_wt=log_wt, frozen_theta0=False):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        # self.theta0 = torch.nn.Parameter(theta0 * torch.ones(1))\n",
    "        self.theta0 = torch.nn.Parameter(torch.tensor(theta0))\n",
    "        if frozen_theta0: self.theta0.requires_grad = False\n",
    "        self.logit0 = torch.nn.Parameter(torch.tensor(logit0))\n",
    "        self.log_wt = torch.nn.Parameter(torch.tensor(log_wt * torch.ones(len(B_thetas))))\n",
    "\n",
    "    def forward(self, theta, i_B_theta):\n",
    "        p0 = self.logit0.sigmoid()\n",
    "        output = p0 / 2. + (1. - p0) * ((theta-self.theta0)/self.log_wt[i_B_theta].exp()).sigmoid()\n",
    "        return output\n",
    "    \n",
    "def fit_data(\n",
    "    theta_trials,\n",
    "    i_B_theta_trials,\n",
    "    y,\n",
    "    logit0=logit0, theta0=theta0, log_wt=log_wt, \n",
    "    learning_rate=learning_rate,\n",
    "    batch_size=batch_size,  \n",
    "    amsgrad=amsgrad, frozen_theta0=frozen_theta0,\n",
    "    num_epochs=num_epochs,\n",
    "    etab1=etab2, etab2=etab2,\n",
    "    verbose=False\n",
    "):\n",
    "\n",
    "\n",
    "    theta_trials, i_B_theta_trials, labels = torch.Tensor(theta_trials[:, None]), torch.Tensor(i_B_theta_trials[:, None]).long(), torch.Tensor(y[:, None])\n",
    "    loader = DataLoader(\n",
    "        TensorDataset(theta_trials, i_B_theta_trials, labels), batch_size=batch_size, shuffle=True\n",
    "    )\n",
    "\n",
    "    total_loss = torch.log(torch.tensor(2)) # criterion(outputs, labels_)\n",
    "        \n",
    "    logistic_model = LogisticRegressionModel(logit0=logit0, log_wt=log_wt, theta0=theta0, frozen_theta0=frozen_theta0)\n",
    "    logistic_model = logistic_model.to(device)\n",
    "    logistic_model.train()\n",
    "    \n",
    "    optimizer = torch.optim.Adam(\n",
    "        logistic_model.parameters(), lr=learning_rate, betas=(1-etab1, 1-etab2), amsgrad=amsgrad\n",
    "    )\n",
    "    for epoch in range(int(num_epochs)):\n",
    "        logistic_model.train()\n",
    "        losses = []\n",
    "        for theta_, i_B_theta_, labels_ in loader:\n",
    "            theta_, i_B_theta_, labels_ = theta_.to(device), i_B_theta_.to(device), labels_.to(device)\n",
    "\n",
    "            # print(theta_, i_B_theta_)\n",
    "            outputs_ = logistic_model(theta_, i_B_theta_)\n",
    "            # print(outputs, labels_)\n",
    "            loss = criterion(outputs_, labels_)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        if verbose and (epoch % (num_epochs // 32) == 0):\n",
    "            print(f\"Iteration: {epoch} - Loss: {np.sum(losses)/len(theta_trials):.3e}\")\n",
    "            # print(f\"Iteration: {epoch} - Evidence: {-np.mean(losses):.3e}\")\n",
    "\n",
    "    logistic_model.eval()\n",
    "    outputs = logistic_model(theta_trials, i_B_theta_trials.long())\n",
    "    loss = criterion(outputs, labels).item()\n",
    "    # loss = - logistic_model.evidence(outputs, labels).item()\n",
    "    return logistic_model, loss / total_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozen_theta0=False\n",
      ".-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*.-*\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3s/q2x8bxzj43g4rdvb2wjt67640000gq/T/ipykernel_76395/3262745140.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.log_wt = torch.nn.Parameter(torch.tensor(log_wt * torch.ones(len(B_thetas))))\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "all elements of input should be between 0 and 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m session \u001b[38;5;129;01min\u001b[39;00m responses.keys():    \n\u001b[32m     16\u001b[39m     y = responses[session]\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m     logistic_model, loss = \u001b[43mfit_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_B_theta_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrozen_theta0\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrozen_theta0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfor \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msession\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, Loss = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m - theta0 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlogistic_model.theta0.item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33mÂ°, p0 = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.sigmoid(logistic_model.logit0).item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, slope = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtorch.exp(logistic_model.log_wt[-\u001b[32m1\u001b[39m]).item()\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2e\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i_B_theta \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(B_thetas)):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 52\u001b[39m, in \u001b[36mfit_data\u001b[39m\u001b[34m(theta_trials, i_B_theta_trials, y, logit0, theta0, log_wt, learning_rate, batch_size, amsgrad, frozen_theta0, num_epochs, etab1, etab2, verbose)\u001b[39m\n\u001b[32m     50\u001b[39m outputs_ = logistic_model(theta_, i_B_theta_)\n\u001b[32m     51\u001b[39m \u001b[38;5;66;03m# print(outputs, labels_)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m loss = \u001b[43mcriterion\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m optimizer.zero_grad()\n\u001b[32m     55\u001b[39m loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:699\u001b[39m, in \u001b[36mBCELoss.forward\u001b[39m\u001b[34m(self, input, target)\u001b[39m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m699\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    700\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mreduction\u001b[49m\n\u001b[32m    701\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.12/site-packages/torch/nn/functional.py:3569\u001b[39m, in \u001b[36mbinary_cross_entropy\u001b[39m\u001b[34m(input, target, weight, size_average, reduce, reduction)\u001b[39m\n\u001b[32m   3566\u001b[39m     new_size = _infer_size(target.size(), weight.size())\n\u001b[32m   3567\u001b[39m     weight = weight.expand(new_size)\n\u001b[32m-> \u001b[39m\u001b[32m3569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_C\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_nn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbinary_cross_entropy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_enum\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: all elements of input should be between 0 and 1"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for the plot\n",
    "x_values = np.linspace(-theta_max, theta_max, 100)[:, None]\n",
    "# Create a colormap\n",
    "cmap = plt.get_cmap('viridis')\n",
    "norm = plt.Normalize(vmin=0, vmax=len(B_thetas) - 1)\n",
    "\n",
    "for frozen_theta0 in [False, True]:\n",
    "\n",
    "    print(f'{frozen_theta0=}')\n",
    "    print(50*'.-*')\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(15, 8))\n",
    "    fig2, ax2 = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "    for session in responses.keys():    \n",
    "        y = responses[session]\n",
    "\n",
    "        logistic_model, loss = fit_data(theta_trials, i_B_theta_trials, y, frozen_theta0=frozen_theta0, verbose=False)\n",
    "        print(f\"for {session}, Loss = {loss:.3e} - theta0 = {logistic_model.theta0.item():.2f}Â°, p0 = {torch.sigmoid(logistic_model.logit0).item():.2e}, slope = {torch.exp(logistic_model.log_wt[-1]).item():.2e}\")\n",
    "\n",
    "        for i_B_theta in range(len(B_thetas)):\n",
    "            y_values = logistic_model(torch.Tensor(x_values), (i_B_theta*torch.ones_like(torch.Tensor(x_values)).long())).detach().numpy()\n",
    "            ax.plot(x_values, y_values, color=cmap(norm(i_B_theta)), alpha=0.5, lw=2, label=f'{i_B_theta}' if session==list(responses.keys())[0] else None)\n",
    "        ax2.plot(B_thetas, logistic_model.log_wt.detach().numpy(), alpha=0.5, lw=2, label=session)\n",
    "\n",
    "    ax.set_xlabel(r\"orientation $\\theta$\", fontsize=20)\n",
    "    ax.axhline(.5, color='k', linestyle='--')\n",
    "    ax.axvline(0., color='b', linestyle='--')\n",
    "    ax.set_yticks([0.0, 1.0])\n",
    "    ax.set_yticklabels([\"CCW\", \"CW\"], fontsize=20)\n",
    "    ax.legend(fontsize=10, frameon=False, scatterpoints=6);\n",
    "\n",
    "\n",
    "    ax2.set_xlabel(r\"orientation precision $B_\\theta$\", fontsize=20)\n",
    "    ax2.set_ylabel(r\"log slope\", fontsize=20)\n",
    "    ax2.legend(fontsize=10, frameon=False, scatterpoints=6);\n",
    "\n",
    "    \n",
    "    plt.show();\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optimize learning parameters with optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_model, loss = fit_data(theta_trials, i_B_theta_trials, y, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "study_name = 'i_B_theta'\n",
    "path_save_optuna = os.path.join('/tmp', f'optuna_{study_name}.sqlite3') # global name\n",
    "# %rm {path_save_optuna}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    vars = dict(verbose = False,  num_epochs=num_epochs//2)\n",
    "    max_threshold = .999\n",
    "    vars['batch_size'] = trial.suggest_int('batch_size', 2, 64, log=True, step=1)\n",
    "    scale = 4\n",
    "    scale = 2\n",
    "    vars['etab1'] = trial.suggest_float('etab1', etab1/scale, min(etab1*scale, max_threshold), log=True)\n",
    "    vars['etab2'] = trial.suggest_float('etab2', etab2/scale, min(etab2*scale, max_threshold), log=True)\n",
    "    vars['learning_rate'] = trial.suggest_float('learning_rate', learning_rate / scale, learning_rate * scale, log=True)\n",
    "    vars['amsgrad'] = trial.suggest_categorical('amsgrad', [True, False])\n",
    "    # initialization\n",
    "    vars['logit0'] = trial.suggest_float('logit0', logit0 - scale, logit0 + scale, log=False)\n",
    "    vars['log_wt'] = trial.suggest_float('log_wt', log_wt - scale, log_wt + scale, log=False)\n",
    "    # vars['theta0'] = trial.suggest_float('theta0', theta0 - scale, theta0 + scale, log=False)\n",
    "\n",
    "    loss = 0\n",
    "    for session in responses.keys():    \n",
    "        y = responses[session]\n",
    "        _, loss_ = fit_data(theta_trials, i_B_theta_trials, y, **vars)\n",
    "        loss += loss_\n",
    "    return loss/len(filenames_valid)\n",
    "\n",
    "print(50*'=')\n",
    "sampler = optuna.samplers.TPESampler(multivariate=True)\n",
    "study = optuna.create_study(direction='minimize', load_if_exists=True, sampler=sampler, storage=f\"sqlite:///{path_save_optuna}\", study_name='LR')\n",
    "study.optimize(objective, n_trials=max((200-len(study.trials), 0)), n_jobs=1, show_progress_bar=True)\n",
    "print(50*'=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(50*'-.')\n",
    "print(f\"Best params: {study.best_params}\")\n",
    "print(f\"Best value: {study.best_value:.3f} at {now.strftime(\"%Y-%m-%d %H:%M:%S\")}\")\n",
    "print(50*'-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
